{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type <class 'list'> [{'nodal': <function mul at 0x000001DC9502DAB0>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}, {'nodal': <function cubic at 0x000001DC9502DBD0>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}, {'nodal': <function sine at 0x000001DC9502DC60>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}, {'nodal': <function expp at 0x000001DC9502DCF0>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}, {'nodal': <function sinh at 0x000001DC9502DD80>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}, {'nodal': <function chirp at 0x000001DC9502E0E0>, 'pool': <built-in function sum>, 'act': <function tanh at 0x000001DC9502E320>}]\n",
      "OpNetwork(\n",
      "  (oper): Sequential(\n",
      "    (0): OpTier(\n",
      "      (oper): ModuleList(\n",
      "        (0-11): 12 x OpBlock()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from fastonn import OpNetwork,utils,OpTier,OpBlock,SelfONN, Trainer\n",
    "from fastonn.osl import *\n",
    "\n",
    "#define the operation set library:\n",
    "OPLIB = getOPLIB(\n",
    "    NODAL = [mul, cubic, sine, expp, sinh, chirp],\n",
    "    POOL = [sum],\n",
    "    ACTIVATION =[tanh] \n",
    ")\n",
    "\n",
    "\n",
    "print('type', type(OPLIB), str(OPLIB))\n",
    "\n",
    "#configure ONN network:\n",
    "model = OpNetwork(\n",
    "    in_channels=1,\n",
    "    tier_sizes=[12], #number of neurons in hidden and input layer\n",
    "    kernel_sizes=[21],\n",
    "    operators=[\n",
    "        [1], #operators for 1st hidden layer\n",
    "    ],\n",
    "    sampling_factors= [2, ], #scaling factors for each layer\n",
    "    OPLIB = OPLIB, #assign operator library\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.adam.Adam'>\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(type(optimizer))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No reset function provided. Generic function will be used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Initialize the trainer instance\\n        - **model** -- progress bar object to update  \\n        - **train_dl** -- training dataloader     \\n        - **val_dl** -- validation dataloader  \\n        - **test_dl** -- test dataloader  \\n        - **loss** -- loss function, must return a PyTorch tensor, not scalar  a\\n        - **opt_name** -- name of the optimizer. Either of  ['adamfast','cgd','adam','vanilla_adam']  \\n        - **lr** -- initial learning rate    \\n        - **metrics** -- Python dictionary with format 'metric_name':(func,max/min), where func is any function with inputs target,output and should return a scalar value for accuracy. max/min defines the desired optimization of this metric  \\n        - **device** -- device on which to train, either of ['cpu','cuda:x'] where x is the index of gpu. Multi-GPU training is not supported yet.    \\n        - **reset_fn** -- function to reset network parameters. Called at the start of each run  \\n        - **track** -- metric to track in format ['mode','metric_name','max/min']  \\n        - **model_name** -- filename of the saved model\\n        - **verbose** -- extent of debug output: 0=No output, 1=show only run progress bar, 2=show run and epoch progress bar  \\n        \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(model, trainloader, testloader, testloader,loss, utils.AdamFast, 0.001, {} ,\"cpu\",)\n",
    "\"\"\"Initialize the trainer instance\n",
    "        - **model** -- progress bar object to update  \n",
    "        - **train_dl** -- training dataloader     \n",
    "        - **val_dl** -- validation dataloader  \n",
    "        - **test_dl** -- test dataloader  \n",
    "        - **loss** -- loss function, must return a PyTorch tensor, not scalar  a\n",
    "        - **opt_name** -- name of the optimizer. Either of  ['adamfast','cgd','adam','vanilla_adam']  \n",
    "        - **lr** -- initial learning rate    \n",
    "        - **metrics** -- Python dictionary with format 'metric_name':(func,max/min), where func is any function with inputs target,output and should return a scalar value for accuracy. max/min defines the desired optimization of this metric  \n",
    "        - **device** -- device on which to train, either of ['cpu','cuda:x'] where x is the index of gpu. Multi-GPU training is not supported yet.    \n",
    "        - **reset_fn** -- function to reset network parameters. Called at the start of each run  \n",
    "        - **track** -- metric to track in format ['mode','metric_name','max/min']  \n",
    "        - **model_name** -- filename of the saved model\n",
    "        - **verbose** -- extent of debug output: 0=No output, 1=show only run progress bar, 2=show run and epoch progress bar  \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x000001DC92556290>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jaakk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\jaakk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py\", line 288, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\jaakk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastonn\\trainer.py:217\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, num_epochs, num_runs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_stats(num_epochs,num_runs)\n\u001b[0;32m    216\u001b[0m runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(num_runs)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m: runs \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m runs:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr \u001b[38;5;241m=\u001b[39m r\n",
      "File \u001b[1;32mc:\\Users\\jaakk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:243\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    242\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaakk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:118\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    120\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
